{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "jumpnet.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNJHvy5INtJBINjs4x+Fmey",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bbi-yggy/keras-jumpnet/blob/main/jumpnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlvAiLRz9C45"
      },
      "source": [
        "# Implementing JumpNet and training with CIFAR-10\n",
        "_Deep Learning for Computer Vision (Cohort #5)_  \n",
        "_Yossarian King / Blackbird Interactive / October 2020_\n",
        "\n",
        "The JumpNet implementation is based on the description from [keras-idiomatic-programmer/zoo/jumpnet](https://github.com/GoogleCloudPlatform/keras-idiomatic-programmer/tree/master/zoo/jumpnet).\n",
        "\n",
        "The implementation is in the idiomatic style - stem > learner > classifier.\n",
        "The learner consists of groups, each composed of blocks, as illustrated here:\n",
        "\n",
        "![JumpNet diagram](https://github.com/GoogleCloudPlatform/keras-idiomatic-programmer/blob/master/zoo/jumpnet/macro.jpg?raw=true)\n",
        "\n",
        "For clarity of implementation, the code has been built as a class with a fluent API, allowing all model metaparameters to be fed into fluent method calls as named parameters. This makes the model structure explicit and the parameters clear, and enables flexible use to build different models in the JumpNet style.\n",
        "\n",
        "Metaparameters used in this notebook precisely mimic the model built by [jumpnet_c.py](https://github.com/GoogleCloudPlatform/keras-idiomatic-programmer/tree/master/zoo/jumpnet/jumpnet_c.py) (see the comment \"Example of JumpNet for CIFAR-10\").\n",
        "\n",
        "The model is trained on [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html), from [Learning Multiple Layers of Features from Tiny Images](https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf), Alex Krizhevsky, 2009.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FvItX2h59BB-"
      },
      "source": [
        "# JumpNet class implementation. This class implements the fluent model-building API.\n",
        "\n",
        "from tensorflow.keras import Input, Model\n",
        "import tensorflow.keras.layers as layers\n",
        "\n",
        "class JumpNet():\n",
        "\n",
        "\tdef __init__(self, shape):\n",
        "\t\tself.inputs = Input(shape)\n",
        "\t\tself.layers = None\n",
        "\t\tself.model = None\n",
        "\n",
        "\tdef stem(self, filters1=16, filters2=32, stride1=1, stride2=1):\n",
        "\t\tself.layers = layers.Conv2D(filters1, (3, 3), strides=stride1, padding='same', use_bias=False)(self.inputs)\n",
        "\t\tself.layers = layers.BatchNormalization()(self.layers)\n",
        "\t\tself.layers = layers.ReLU()(self.layers)\n",
        "\n",
        "\t\tself.layers = layers.Conv2D(filters2, (3, 3), strides=stride2, padding='same', use_bias=False)(self.layers)\n",
        "\t\tself.layers = layers.BatchNormalization()(self.layers)\n",
        "\t\tself.layers = layers.ReLU()(self.layers)\n",
        "\t\treturn self\n",
        "\n",
        "\tdef group(self, filters, blocks, blockfilters=None):\n",
        "\t\tshortcut = layers.BatchNormalization()(self.layers)\n",
        "\t\tshortcut = layers.Conv2D(filters, (1,1), strides=(2,2), use_bias=False)(shortcut)\n",
        "\n",
        "\t\tfor _ in range(blocks):\n",
        "\t\t\tself.block(filters, blockfilters)\n",
        "\n",
        "\t\tself.layers = layers.BatchNormalization()(self.layers)\n",
        "\t\tself.layers = layers.ReLU()(self.layers)\n",
        "\t\tself.layers = layers.Conv2D(filters, (1,1), strides=(2,2), use_bias=False)(self.layers)\n",
        "\n",
        "\t\tself.layers = layers.Concatenate()([shortcut, self.layers])\n",
        "\t\treturn self\n",
        "\n",
        "\tdef block(self, filters, blockfilters=None):\n",
        "\t\tshortcut = self.layers\n",
        "\n",
        "\t\tblockfilters = blockfilters or filters\n",
        "\t\tself.layers = layers.BatchNormalization()(self.layers)\n",
        "\t\tself.layers = layers.ReLU()(self.layers)\n",
        "\t\tself.layers = layers.Conv2D(blockfilters, (1,1), strides=(1,1), use_bias=False)(self.layers)\n",
        "\n",
        "\t\tself.layers = layers.BatchNormalization()(self.layers)\n",
        "\t\tself.layers = layers.ReLU()(self.layers)\n",
        "\t\tself.layers = layers.Conv2D(blockfilters, (3,3), strides=(1,1), padding='same', use_bias=False)(self.layers)\n",
        "\n",
        "\t\tself.layers = layers.BatchNormalization()(self.layers)\n",
        "\t\tself.layers = layers.ReLU()(self.layers)\n",
        "\t\tself.layers = layers.Conv2D(filters, (1,1), strides=(1,1), use_bias=False)(self.layers)\n",
        "\n",
        "\t\tself.layers = layers.Add()([shortcut, self.layers])\n",
        "\t\treturn self\n",
        "\t\n",
        "\tdef classifier(self, classes):\n",
        "\t\tself.layers = layers.GlobalAveragePooling2D()(self.layers)\n",
        "\t\tself.layers = layers.Dense(classes)(self.layers)\n",
        "\t\tself.layers = layers.Activation('softmax')(self.layers)\n",
        "\t\tself.outputs = self.layers\n",
        "\t\tself.model = Model(self.inputs, self.outputs)\n",
        "\t\treturn self\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgFXXsNIETZh"
      },
      "source": [
        "With this class, we can build a JumpNet model to be trained with the CIFAR-10 dataset.\n",
        "\n",
        "Here we see the fluent API in action, and metaparameters exposed as named arguments. (The enclosing parentheses are to enable the multi-line statement with having to end lines with backslashes.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-J7kRrWEfsP"
      },
      "source": [
        "jumpnet = (\n",
        "\tJumpNet(shape=(32, 32, 3))\n",
        "\t.stem()\n",
        "\t.group(filters=32, blocks=3)\n",
        "\t.group(filters=64, blocks=4)\n",
        "\t.group(filters=128, blocks=3)\n",
        "\t.classifier(classes=10)\n",
        ")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5ESIchPEwvR"
      },
      "source": [
        "So, what does that model look like?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8YhJzjZEyqB",
        "outputId": "58a99ed1-26a9-4947-fc61-c0e3a38b4571",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "jumpnet.model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 16)   432         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 16)   64          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "re_lu (ReLU)                    (None, 32, 32, 16)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 32)   4608        re_lu[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 32)   128         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_1 (ReLU)                  (None, 32, 32, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 32)   128         re_lu_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_2 (ReLU)                  (None, 32, 32, 32)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 32)   1024        re_lu_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 32)   128         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_3 (ReLU)                  (None, 32, 32, 32)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 32)   9216        re_lu_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 32)   128         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_4 (ReLU)                  (None, 32, 32, 32)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 32)   1024        re_lu_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 32, 32, 32)   0           re_lu_1[0][0]                    \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 32)   128         add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_5 (ReLU)                  (None, 32, 32, 32)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 32)   1024        re_lu_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 32)   128         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_6 (ReLU)                  (None, 32, 32, 32)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 32)   9216        re_lu_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 32)   128         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_7 (ReLU)                  (None, 32, 32, 32)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 32)   1024        re_lu_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 32, 32)   0           add[0][0]                        \n",
            "                                                                 conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 32)   128         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_8 (ReLU)                  (None, 32, 32, 32)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 32)   1024        re_lu_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 32, 32, 32)   128         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_9 (ReLU)                  (None, 32, 32, 32)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 32)   9216        re_lu_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 32, 32, 32)   128         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_10 (ReLU)                 (None, 32, 32, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 32)   1024        re_lu_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 32, 32, 32)   0           add_1[0][0]                      \n",
            "                                                                 conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 32, 32)   128         add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 32)   128         re_lu_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_11 (ReLU)                 (None, 32, 32, 32)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 16, 16, 32)   1024        batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 32)   1024        re_lu_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 16, 16, 64)   0           conv2d_2[0][0]                   \n",
            "                                                                 conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   256         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_12 (ReLU)                 (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   4096        re_lu_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   256         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_13 (ReLU)                 (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   36864       re_lu_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 64)   256         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_14 (ReLU)                 (None, 16, 16, 64)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 64)   4096        re_lu_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 16, 16, 64)   0           concatenate[0][0]                \n",
            "                                                                 conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 64)   256         add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_15 (ReLU)                 (None, 16, 16, 64)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 64)   4096        re_lu_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   256         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_16 (ReLU)                 (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   36864       re_lu_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   256         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_17 (ReLU)                 (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   4096        re_lu_17[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 16, 16, 64)   0           add_3[0][0]                      \n",
            "                                                                 conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 64)   256         add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_18 (ReLU)                 (None, 16, 16, 64)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 64)   4096        re_lu_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   256         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_19 (ReLU)                 (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   36864       re_lu_19[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   256         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_20 (ReLU)                 (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   4096        re_lu_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 16, 16, 64)   0           add_4[0][0]                      \n",
            "                                                                 conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 64)   256         add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_21 (ReLU)                 (None, 16, 16, 64)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 64)   4096        re_lu_21[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 64)   256         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_22 (ReLU)                 (None, 16, 16, 64)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 64)   36864       re_lu_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   256         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_23 (ReLU)                 (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   4096        re_lu_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 16, 16, 64)   0           add_5[0][0]                      \n",
            "                                                                 conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 16, 16, 64)   256         add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 64)   256         concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_24 (ReLU)                 (None, 16, 16, 64)   0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 8, 8, 64)     4096        batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 8, 8, 64)     4096        re_lu_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 8, 8, 128)    0           conv2d_13[0][0]                  \n",
            "                                                                 conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 8, 8, 128)    512         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_25 (ReLU)                 (None, 8, 8, 128)    0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 8, 8, 128)    16384       re_lu_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 8, 8, 128)    512         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_26 (ReLU)                 (None, 8, 8, 128)    0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 8, 8, 128)    147456      re_lu_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 8, 8, 128)    512         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_27 (ReLU)                 (None, 8, 8, 128)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 8, 8, 128)    16384       re_lu_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 8, 8, 128)    0           concatenate_1[0][0]              \n",
            "                                                                 conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 8, 8, 128)    512         add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_28 (ReLU)                 (None, 8, 8, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 8, 8, 128)    16384       re_lu_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 8, 8, 128)    512         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_29 (ReLU)                 (None, 8, 8, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 8, 8, 128)    147456      re_lu_29[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 8, 8, 128)    512         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_30 (ReLU)                 (None, 8, 8, 128)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 8, 8, 128)    16384       re_lu_30[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 8, 8, 128)    0           add_7[0][0]                      \n",
            "                                                                 conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 8, 8, 128)    512         add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_31 (ReLU)                 (None, 8, 8, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 8, 8, 128)    16384       re_lu_31[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 8, 8, 128)    512         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_32 (ReLU)                 (None, 8, 8, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 8, 8, 128)    147456      re_lu_32[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 8, 8, 128)    512         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_33 (ReLU)                 (None, 8, 8, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 8, 8, 128)    16384       re_lu_33[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 8, 8, 128)    0           add_8[0][0]                      \n",
            "                                                                 conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 8, 8, 128)    512         add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 8, 8, 128)    512         concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_34 (ReLU)                 (None, 8, 8, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 4, 4, 128)    16384       batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 4, 4, 128)    16384       re_lu_34[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 4, 4, 256)    0           conv2d_27[0][0]                  \n",
            "                                                                 conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 256)          0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           2570        global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 10)           0           dense[0][0]                      \n",
            "==================================================================================================\n",
            "Total params: 816,122\n",
            "Trainable params: 810,714\n",
            "Non-trainable params: 5,408\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dagAuG0uFKB0"
      },
      "source": [
        "Now let's get the CIFAR-10 dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6en7WTAFMgw",
        "outputId": "e5617509-34f5-4525-913b-df36487a9512",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLyfrnM5Ff1j"
      },
      "source": [
        "Now we can compile and train the model. The training program is naive, we'll just run 200 epochs and hope the model stablizes. This is going to take a while - as of this writing it's about 30 seconds per epoch, times 200 epochs is an hour and forty minutes. Now would be a good time to go get a coffee. \n",
        "☕"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9N6k7x0FpGh",
        "outputId": "3be7c4ff-f83c-4daf-de59-073a6af69fc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "jumpnet.model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "history = jumpnet.model.fit(train_images, train_labels, epochs=200, validation_data=(test_images, test_labels))\n",
        "test_loss, test_acc = jumpnet.model.evaluate(test_images,  test_labels, verbose=2)\n",
        "\n",
        "print(\"test accuracy\", test_acc)\n",
        "print(\"test loss\", test_loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 2.0481 - accuracy: 0.4075 - val_loss: 2.0929 - val_accuracy: 0.3624\n",
            "Epoch 2/200\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 1.9403 - accuracy: 0.5161 - val_loss: 2.0200 - val_accuracy: 0.4343\n",
            "Epoch 3/200\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 1.8824 - accuracy: 0.5757 - val_loss: 1.9671 - val_accuracy: 0.4891\n",
            "Epoch 4/200\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 1.8519 - accuracy: 0.6058 - val_loss: 1.9825 - val_accuracy: 0.4740\n",
            "Epoch 5/200\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 1.8294 - accuracy: 0.6297 - val_loss: 1.9466 - val_accuracy: 0.5105\n",
            "Epoch 6/200\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 1.8146 - accuracy: 0.6443 - val_loss: 1.8304 - val_accuracy: 0.6272\n",
            "Epoch 7/200\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 1.7997 - accuracy: 0.6593 - val_loss: 1.8351 - val_accuracy: 0.6227\n",
            "Epoch 8/200\n",
            "1563/1563 [==============================] - 29s 19ms/step - loss: 1.7879 - accuracy: 0.6705 - val_loss: 1.8615 - val_accuracy: 0.5957\n",
            "Epoch 9/200\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 1.7764 - accuracy: 0.6821 - val_loss: 1.8044 - val_accuracy: 0.6545\n",
            "Epoch 10/200\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 1.7704 - accuracy: 0.6891 - val_loss: 1.8048 - val_accuracy: 0.6545\n",
            "Epoch 11/200\n",
            "1549/1563 [============================>.] - ETA: 0s - loss: 1.7615 - accuracy: 0.6979"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}